{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cb8bd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------------------LIBRARIES--------------------------------------------------------------------------------------------                                                                                         #import OpenCV2 library for image processing and algorithms\n",
    "import math\n",
    "import csv \n",
    "import numpy as np                                                                                     #import numpy mathematical library\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt      #import matplotlib library for plotting\n",
    "from micromlgen import port\n",
    "\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))                                  #change width of Jupyer Notebook to use the whole window resolution available\n",
    "from IPython.display import display\n",
    "\n",
    "# import the regressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import *\n",
    "from sklearn import tree\n",
    "from dtreeviz.trees import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35673eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(errors, y_pred, filename, name):\n",
    "    plt.plot(errors)\n",
    "    plt.xticks(ticks=[i for i in range(len(errors))], labels=y_pred)\n",
    "    plt.xlabel('Predicted Value')\n",
    "    plt.ylabel(name)\n",
    "    plt.savefig(filename, dpi=500)                                                                                     #https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib\n",
    "    plt.show()\n",
    "    \n",
    "def save_statistics(clf, X_train, y_train, X_test, y_true, csv_filename, mae_filename, mse_filename, metrics_filename):\n",
    "    y_pred = []\n",
    "    with open(csv_filename, \"a\", newline='') as fp:\n",
    "        for row in X_test:\n",
    "            result = float((str(clf.predict(row.reshape(1, -1))).replace('[','').replace(']','')))\n",
    "            y_pred.append(result)\n",
    "            wr = csv.writer(fp, dialect='excel')\n",
    "            wr.writerow([result])\n",
    "    fp.close()\n",
    "    \n",
    "    #https://machinelearningmastery.com/regression-metrics-for-machine-learning/\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
    "    metrics = {\"Mean Squared Error: \" : mean_squared_error(y_true, y_pred),\n",
    "               \"Root Mean Squared Error: \" : mean_squared_error(y_true, y_pred, squared=False), \n",
    "               \"Mean Absolute Error: \" : mean_absolute_error(y_true, y_pred),\n",
    "               \"Mean Deviation Error: \" : str((abs((sum(y_true) / len(y_true))-(sum(y_pred) / len(y_pred))) / (sum(y_true) / len(y_true))))[1:-1],\n",
    "               \"R2 Score - Uniform Average: \" : r2_score(y_true, y_pred), \n",
    "               \"R2 Score - Variance Weighted: \" : r2_score(y_true, y_pred, multioutput='variance_weighted')}\n",
    "    \n",
    "    # calculate errors\n",
    "    mae_errors, mse_errors = [], []\n",
    "    for i in range(len(y_true)):\n",
    "        mae = abs((y_true[i] - y_pred[i]))               #calculate mean absolute error\n",
    "        mse = (y_true[i] - y_pred[i])**2                 #calculate mean squared error\n",
    "        mae_errors.append(mae)                           #store mea error\n",
    "        mse_errors.append(mse)                           #store mse error\n",
    "        \n",
    "    #plot mean errors\n",
    "    plot_error(mae_errors, y_pred, mae_filename, \"Mean Absolute Error\")\n",
    "    plot_error(mse_errors, y_pred, mse_filename, \"Mean Squared Error\")\n",
    "    \n",
    "    with open(metrics_filename, 'w') as f:\n",
    "        for k, v in metrics.items():\n",
    "            f.write(str(k) + str(v) + '\\n\\n')\n",
    "            print(str(k) + str(v))\n",
    "    f.close()\n",
    "    \n",
    "    #https://mljar.com/blog/visualize-decision-tree/  &  https://github.com/parrt/dtreeviz\n",
    "    viz = dtreeviz(dtr,X_train, y_train, target_name='precipitation', \n",
    "                   feature_names=[\"Temperature\", \"Feels Like\", \"Dew Point\", \"Humidity\", \"Pressure\"], \n",
    "                                         class_names=[\"Fair\", \"Rain\", \"Cloudy\", \"Overcast\", \"Snow\"])\n",
    "    viz.view() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d86c66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Train Dataset is:  weather_data_2000_2019\n",
      "Your Test Dataset is:  weather_data_2020_2021\n",
      "Please choose 1 to display the dataset or any button to cotinue without displaying!1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   7.9 ,    7.5 ,    6.9 ,   93.72, 1024.5 ],\n",
       "       [   8.4 ,    7.7 ,    6.7 ,   89.02, 1025.3 ],\n",
       "       [   9.1 ,    8.7 ,    7.8 ,   91.37, 1018.6 ],\n",
       "       ...,\n",
       "       [   7.4 ,    5.1 ,    5.2 ,   85.75, 1033.6 ],\n",
       "       [   6.8 ,    5.3 ,    5.7 ,   93.15, 1029.7 ],\n",
       "       [   7.3 ,    5.6 ,    6.5 ,   94.87, 1031.6 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.4 , 0.69, 0.83, ..., 0.  , 0.  , 0.  ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   5.4 ,    4.  ,    3.9 ,   90.37, 1029.3 ],\n",
       "       [   8.8 ,    7.2 ,    7.1 ,   89.27, 1020.4 ],\n",
       "       [   8.3 ,    6.4 ,    5.2 ,   81.85, 1021.4 ],\n",
       "       ...,\n",
       "       [  11.2 ,   10.6 ,    9.1 ,   87.68, 1004.2 ],\n",
       "       [  14.  ,   14.  ,   12.  ,   87.59, 1012.3 ],\n",
       "       [  13.6 ,   13.6 ,   11.  ,   84.72, 1016.5 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose 1 for Training and 2 for Random CV Search. \n",
      "                       Pressing 3 will load the optimised Decision Tree Regressor model!1\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #dataset selection and loading\n",
    "    train_set_name = \"weather_data_2000_2019\"\n",
    "    train_dataset = pd.read_csv((\"./datasets/\" + train_set_name + \".csv\"),header=None)\n",
    "    test_set_name = \"weather_data_2020_2021\"\n",
    "    test_dataset = pd.read_csv((\"./datasets/\" + test_set_name + \".csv\"),header=None) \n",
    "\n",
    "    print(\"Your Train Dataset is: \", train_set_name)                                                                       #display dataset name to user\n",
    "    print(\"Your Test Dataset is: \", test_set_name)                                                                       #display dataset name to user\n",
    "\n",
    "    features_selected = 5\n",
    "    #training features\n",
    "    temperature_train = train_dataset.iloc[:, 4:5]\n",
    "    feels_like_train = train_dataset.iloc[:, 7:8]\n",
    "    dew_point_train = train_dataset.iloc[:, 8:9]\n",
    "    humidity_train = train_dataset.iloc[:, 9:10]\n",
    "    pressure_train = train_dataset.iloc[:, 19:20] \n",
    "    uv_index_train = train_dataset.iloc[:, 24:25] \n",
    "\n",
    "    #testing data\n",
    "    temperature_test = test_dataset.iloc[:, 4:5]\n",
    "    feels_like_test = test_dataset.iloc[:, 7:8]\n",
    "    dew_point_test = test_dataset.iloc[:, 8:9]\n",
    "    humidity_true = test_dataset.iloc[:, 9:10]\n",
    "    pressure_test = test_dataset.iloc[:, 19:20]\n",
    "    uv_index_test = test_dataset.iloc[:, 24:25] \n",
    "\n",
    "    X_train = pd.concat([temperature_train, feels_like_train, dew_point_train, humidity_train, pressure_train], axis=1)  #, uv_index_train], axis=1)\n",
    "    X_train.replace(([np.inf, -np.inf], np.nan), inplace=True)                                                            #replace any infinite values with nan\n",
    "    X_train = X_train.to_numpy()  \n",
    "\n",
    "\n",
    "    y_train = train_dataset.iloc[:, 10:11].to_numpy()\n",
    "    y_true = test_dataset.iloc[:, 10:11].to_numpy()\n",
    "\n",
    "    #https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "    test_data = pd.concat([temperature_test, feels_like_test, dew_point_test, humidity_true, pressure_test], axis=1)  #, uv_index_test], axis=1)       \n",
    "    test_data.replace(([np.inf, -np.inf], np.nan), inplace=True)                                                            #replace any infinite values with nan\n",
    "    X_test = test_data.to_numpy()\n",
    "\n",
    "    #change all nan values in all datasets with the most frequent value of the dataset\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    imp.fit(X_train)\n",
    "    imp.fit(y_train)\n",
    "    imp.fit(X_test)\n",
    "    imp.fit(y_true)\n",
    "\n",
    "    disp = int(input(\"Please choose 1 to display the dataset or any button to cotinue without displaying!\"))\n",
    "    if disp == 1:\n",
    "        display(X_train)\n",
    "        display(y_train.ravel())\n",
    "\n",
    "        display(X_test)\n",
    "    else: print(\"Not displaying dataset!\")   \n",
    "\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    choice = int(input(\"\"\"Please choose 1 for Training and 2 for Random CV Search. \n",
    "                       Pressing 3 will load the optimised Decision Tree Regressor model!\"\"\"))\n",
    "    clf_type = \"default\" if choice == 1 else \"optimised\"\n",
    "    model_name = \"./trained_models/dtr_optimised_\" + train_set_name + \"_\" + test_set_name + \"_\" + str(features_selected) + \"f.p\"\n",
    "    mae_filename = \"./plots/dtr_mae\" + str(clf_type) + \"_\" + train_set_name + \"_\"  + test_set_name + \"_\" + str(features_selected) + \"f.png\"\n",
    "    mse_filename = \"./plots/dtr_mse\" + str(clf_type) + \"_\" + train_set_name + \"_\"  + test_set_name + \"_\" + str(features_selected) + \"f.png\"\n",
    "    metrics_filename = \"./metrics/dtr_\" + str(clf_type) + \"_\" + train_set_name + \"_\"  + test_set_name + \"_\" + str(features_selected) + \"f.txt\"\n",
    "    csv_filename = \"./outputs/output_dtr_\"  + str(clf_type) + \"_\" + train_set_name + \"_\"  + test_set_name + \"_\" + str(features_selected) + \"f.csv\"\n",
    "\n",
    "    if choice == 1:\n",
    "        # Create Random Forest classifer object and train it on the selected dataset\n",
    "        dtr = (tree.DecisionTreeRegressor(max_depth=6, random_state = 0)).fit(X_train, y_train.ravel())\n",
    "        \n",
    "        #get statistics and plot errors\n",
    "        save_statistics(dtr, X_train, y_train, X_test, y_true, csv_filename, mae_filename, mse_filename, metrics_filename)  \n",
    "        \n",
    "    elif choice == 2:\n",
    "        dtr = tree.DecisionTreeRegressor(random_state = 0)\n",
    "        parameters={\n",
    "                   \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "                   \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "                   \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5],\n",
    "                   \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "                   \"max_leaf_nodes\":[2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]}\n",
    "        grid_search = GridSearchCV(dtr, param_grid=parameters, scoring='r2', cv=5, verbose=1, refit = True, n_jobs = -1)\n",
    "        grid_search.fit(X_train, y_train.ravel())\n",
    "\n",
    "        print(grid_search.best_params_)                                                                                           # print best parameter after tuning\n",
    "        print(grid_search.best_estimator_)                                                                                        # print how our model looks after hyper-parameter tuning\n",
    "        pickle.dump(grid_search.best_estimator_, open(model_name, \"wb\"))\n",
    "\n",
    "    elif choice == 3:\n",
    "        dtr = pickle.load(open(model_name, \"rb\"))\n",
    "        print(\"Parameters Classifier Loaded: \", dtr.get_params())\n",
    "\n",
    "        save_statistics(dtr, X_train, y_train, X_test, y_true, csv_filename, mae_filename, mse_filename, metrics_filename)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":                                                                                               #guard boilerplate\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
